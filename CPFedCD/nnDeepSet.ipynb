{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe3cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed=100\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9407b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Permutation Invariant layers and Permutation Equivariant, as described in the\n",
    "paper Deep Sets, by Zaheer et al. (https://arxiv.org/abs/1703.06114)\n",
    "\"\"\"\n",
    "#FeatureExtractor\n",
    "\n",
    "class InvLinear(nn.Module):\n",
    "\n",
    "    r\"\"\"Permutation invariant linear layer.\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        reduction: Permutation invariant operation that maps the input set into a single\n",
    "            vector. Currently, the following are supported: mean, sum, max and min.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True, reduction='mean'):\n",
    "        super(InvLinear, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        assert reduction in ['mean', 'sum', 'max', 'min'],  \\\n",
    "            '\\'reduction\\' should be \\'mean\\'/\\'sum\\'\\'max\\'/\\'min\\', got {}'.format(reduction)\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.beta = nn.Parameter(torch.Tensor(self.in_features,\n",
    "                                              self.out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(1, self.out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.beta)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.beta)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        r\"\"\"\n",
    "        Maps the input set X = {x_1, ..., x_M} to a vector y of dimension out_features,\n",
    "        through a permutation invariant linear transformation of the form:\n",
    "            $y = \\beta reduction(X) + bias$\n",
    "        Inputs:\n",
    "        X: N sets of size at most M where each element has dimension in_features\n",
    "           (tensor with shape (N, M, in_features))\n",
    "        mask: binary mask to indicate which elements in X are valid (byte tensor\n",
    "            with shape (N, M) or None); if None, all sets have the maximum size M.\n",
    "            Default: ``None``.\n",
    "        Outputs:\n",
    "        Y: N vectors of dimension out_features (tensor with shape (N, out_features))\n",
    "        \"\"\"\n",
    "        N, M, _ = X.shape\n",
    "        device = X.device\n",
    "        y = torch.zeros(N, self.out_features).to(device)\n",
    "        if mask is None:\n",
    "            mask = torch.ones(N, M).byte().to(device)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = (Z.sum(dim=1) @ self.beta)/sizes\n",
    "\n",
    "        elif self.reduction == 'sum':\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = Z.sum(dim=1) @ self.beta\n",
    "\n",
    "        elif self.reduction == 'max':\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('-Inf')\n",
    "            y = Z.max(dim=1)[0] @ self.beta\n",
    "\n",
    "        else:  # min\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('Inf')\n",
    "            y = Z.min(dim=1)[0] @ self.beta\n",
    "\n",
    "        if self.bias is not None:\n",
    "            y += self.bias\n",
    "\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}, reduction={}'.format(\n",
    "            self.in_features, self.out_features,\n",
    "            self.bias is not None, self.reduction)\n",
    "\n",
    "\n",
    "class EquivLinear(InvLinear):\n",
    "    r\"\"\"Permutation equivariant linear layer.\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        reduction: Permutation invariant operation that maps the input set into a single\n",
    "            vector. Currently, the following are supported: mean, sum, max and min.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True, reduction='mean'):\n",
    "        super(EquivLinear, self).__init__(in_features, out_features,\n",
    "                                          bias=bias, reduction=reduction)\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.Tensor(self.in_features,\n",
    "                                               self.out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super(EquivLinear, self).reset_parameters()\n",
    "        if hasattr(self, 'alpha'):\n",
    "            init.xavier_uniform_(self.alpha)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        r\"\"\"\n",
    "        Maps the input set X = {x_1, ..., x_M} to the output set\n",
    "        Y = {y_1, ..., y_M} through a permutation equivariant linear transformation\n",
    "        of the form:\n",
    "            $y_i = \\alpha x_i + \\beta reduction(X) + bias$\n",
    "        Inputs:\n",
    "        X: N sets of size at most M where each element has dimension in_features\n",
    "           (tensor with shape (N, M, in_features))\n",
    "        mask: binary mask to indicate which elements in X are valid (byte tensor\n",
    "            with shape (N, M) or None); if None, all sets have the maximum size M.\n",
    "            Default: ``None``.\n",
    "        Outputs:\n",
    "        Y: N sets of same cardinality as in X where each element has dimension\n",
    "           out_features (tensor with shape (N, M, out_features))\n",
    "        \"\"\"\n",
    "        N, M, _ = X.shape\n",
    "        device = X.device\n",
    "        Y = torch.zeros(N, M, self.out_features).to(device)\n",
    "        if mask is None:\n",
    "            mask = torch.ones(N, M).byte().to(device)\n",
    "\n",
    "        Y = torch.zeros(N, M, self.out_features).to(device)\n",
    "        h_inv = super(EquivLinear, self).forward(X, mask=mask)\n",
    "        Y[mask] = (X @ self.alpha + h_inv.unsqueeze(1))[mask]\n",
    "\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94d72b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44486, 59)\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('D:/Program Files/R/Rfile/SC_FL_CD/1023/alltrain.csv')\n",
    "df = pd.read_csv('D:/Program Files/R/Rfile/SC_FL_CD/1023/valtrain.csv')\n",
    "print(df.shape)\n",
    "#print(df.head())\n",
    "df= df.apply(pd.to_numeric,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "siteid = np.array(df['hospitalid'])\n",
    "id = np.unique(siteid)\n",
    "print(id)\n",
    "print(len(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef4096e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from kmodes.kmodes import KModes\n",
    "\n",
    "#onedf = df[df['hospitalid']==79]\n",
    "#onedt = onedf.drop(['hospitalid'],axis=1)\n",
    "#print(onedf.shape)\n",
    "\n",
    "#km = KModes(n_clusters=5,init='Huang',n_init=5,verbose=1)\n",
    "#clusters =km.fit_predict(onedt)#\n",
    "#print(km.cluster_centroids_)#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "dtlist = []          ## \n",
    "\n",
    "for i in range(len(id)):\n",
    "    np.random.seed(seed)\n",
    "    print('this is runing:',i)\n",
    "    onedf = df[df['hospitalid']==id[i]]\n",
    "    onedt = onedf.drop(['hospitalid'],axis=1)#\n",
    "    #path='E:/deepset/site%s'% id[i]+'.csv'\n",
    "    #onedt.to_csv(path,index=False)\n",
    "    \n",
    "    km = KModes(n_clusters=10,init='Huang',n_init=5,verbose=1)\n",
    "    clusters =km.fit_predict(onedt)\n",
    "    kmc= km.cluster_centroids_\n",
    "    dtlist.append(kmc)   ## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c37d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d70ac75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = np.array(dtlist)\n",
    "t = torch.tensor(data_list,dtype= torch.float)\n",
    "\n",
    "##\n",
    "deep_sets = InvLinear(in_features=58, out_features=10)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = deep_sets.forward(t)\n",
    "y =  y1.detach().numpy()\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ca04fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.to_csv('E:/deepset/vc1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4af7a3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.343514</td>\n",
       "      <td>-0.470205</td>\n",
       "      <td>-5.780606</td>\n",
       "      <td>1.961841</td>\n",
       "      <td>-1.940944</td>\n",
       "      <td>1.399573</td>\n",
       "      <td>-0.673334</td>\n",
       "      <td>-2.169806</td>\n",
       "      <td>-0.438555</td>\n",
       "      <td>-1.526194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.468988</td>\n",
       "      <td>-0.463305</td>\n",
       "      <td>-5.871291</td>\n",
       "      <td>1.982735</td>\n",
       "      <td>-1.889553</td>\n",
       "      <td>1.412642</td>\n",
       "      <td>-0.520311</td>\n",
       "      <td>-2.189789</td>\n",
       "      <td>-0.365389</td>\n",
       "      <td>-1.491480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.511020</td>\n",
       "      <td>-0.452256</td>\n",
       "      <td>-5.814909</td>\n",
       "      <td>2.135624</td>\n",
       "      <td>-1.987322</td>\n",
       "      <td>1.300354</td>\n",
       "      <td>-0.469966</td>\n",
       "      <td>-2.525029</td>\n",
       "      <td>-0.454924</td>\n",
       "      <td>-1.668514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.562456</td>\n",
       "      <td>-0.198412</td>\n",
       "      <td>-5.874629</td>\n",
       "      <td>2.334005</td>\n",
       "      <td>-2.022654</td>\n",
       "      <td>1.461627</td>\n",
       "      <td>-0.308126</td>\n",
       "      <td>-2.261543</td>\n",
       "      <td>-0.714481</td>\n",
       "      <td>-1.573503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.438083</td>\n",
       "      <td>-0.645153</td>\n",
       "      <td>-5.910209</td>\n",
       "      <td>2.030208</td>\n",
       "      <td>-1.800816</td>\n",
       "      <td>1.501837</td>\n",
       "      <td>-0.417466</td>\n",
       "      <td>-2.207183</td>\n",
       "      <td>-0.373309</td>\n",
       "      <td>-1.511065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.478323</td>\n",
       "      <td>-0.378768</td>\n",
       "      <td>-5.769333</td>\n",
       "      <td>2.025003</td>\n",
       "      <td>-1.893234</td>\n",
       "      <td>1.627165</td>\n",
       "      <td>-0.494353</td>\n",
       "      <td>-2.301847</td>\n",
       "      <td>-0.527648</td>\n",
       "      <td>-1.520270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.504324</td>\n",
       "      <td>-0.588872</td>\n",
       "      <td>-5.946111</td>\n",
       "      <td>1.963259</td>\n",
       "      <td>-1.849977</td>\n",
       "      <td>1.485801</td>\n",
       "      <td>-0.706335</td>\n",
       "      <td>-2.229362</td>\n",
       "      <td>-0.316175</td>\n",
       "      <td>-1.557958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.479429</td>\n",
       "      <td>-0.530021</td>\n",
       "      <td>-5.837025</td>\n",
       "      <td>2.141378</td>\n",
       "      <td>-2.090778</td>\n",
       "      <td>1.547986</td>\n",
       "      <td>-0.558126</td>\n",
       "      <td>-2.502913</td>\n",
       "      <td>-0.464672</td>\n",
       "      <td>-1.473361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.414129</td>\n",
       "      <td>-0.365094</td>\n",
       "      <td>-6.136842</td>\n",
       "      <td>2.138390</td>\n",
       "      <td>-2.010524</td>\n",
       "      <td>1.420078</td>\n",
       "      <td>-0.367815</td>\n",
       "      <td>-2.320865</td>\n",
       "      <td>-0.614544</td>\n",
       "      <td>-1.740168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4.542788</td>\n",
       "      <td>-0.681623</td>\n",
       "      <td>-5.881545</td>\n",
       "      <td>2.023903</td>\n",
       "      <td>-2.266980</td>\n",
       "      <td>1.632286</td>\n",
       "      <td>-0.901849</td>\n",
       "      <td>-2.412902</td>\n",
       "      <td>-0.430513</td>\n",
       "      <td>-1.623027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-4.425818</td>\n",
       "      <td>-0.689757</td>\n",
       "      <td>-5.806067</td>\n",
       "      <td>2.111423</td>\n",
       "      <td>-2.031722</td>\n",
       "      <td>1.469004</td>\n",
       "      <td>-0.759572</td>\n",
       "      <td>-2.307801</td>\n",
       "      <td>-0.607591</td>\n",
       "      <td>-1.600415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-4.527795</td>\n",
       "      <td>-0.568058</td>\n",
       "      <td>-5.848974</td>\n",
       "      <td>1.994722</td>\n",
       "      <td>-1.967229</td>\n",
       "      <td>1.660657</td>\n",
       "      <td>-0.609224</td>\n",
       "      <td>-2.246560</td>\n",
       "      <td>-0.651440</td>\n",
       "      <td>-1.632452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-4.566021</td>\n",
       "      <td>-0.158057</td>\n",
       "      <td>-5.641023</td>\n",
       "      <td>2.227514</td>\n",
       "      <td>-1.876553</td>\n",
       "      <td>1.791280</td>\n",
       "      <td>-0.359609</td>\n",
       "      <td>-2.079988</td>\n",
       "      <td>-0.849005</td>\n",
       "      <td>-1.845268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-4.515719</td>\n",
       "      <td>-0.527349</td>\n",
       "      <td>-5.812649</td>\n",
       "      <td>2.197331</td>\n",
       "      <td>-1.981195</td>\n",
       "      <td>1.678271</td>\n",
       "      <td>-0.517956</td>\n",
       "      <td>-2.225466</td>\n",
       "      <td>-0.500846</td>\n",
       "      <td>-1.490168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-4.415989</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-5.693619</td>\n",
       "      <td>2.100939</td>\n",
       "      <td>-2.035962</td>\n",
       "      <td>1.558091</td>\n",
       "      <td>-0.646224</td>\n",
       "      <td>-2.313899</td>\n",
       "      <td>-0.452682</td>\n",
       "      <td>-1.717500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-4.204714</td>\n",
       "      <td>-0.624371</td>\n",
       "      <td>-6.104282</td>\n",
       "      <td>2.207796</td>\n",
       "      <td>-2.011225</td>\n",
       "      <td>1.520842</td>\n",
       "      <td>-0.869734</td>\n",
       "      <td>-2.228696</td>\n",
       "      <td>-0.431966</td>\n",
       "      <td>-1.647368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-4.417226</td>\n",
       "      <td>-0.410155</td>\n",
       "      <td>-5.668110</td>\n",
       "      <td>2.149332</td>\n",
       "      <td>-2.028780</td>\n",
       "      <td>1.590480</td>\n",
       "      <td>-0.309961</td>\n",
       "      <td>-2.133852</td>\n",
       "      <td>-0.686246</td>\n",
       "      <td>-1.767470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.491939</td>\n",
       "      <td>-0.725661</td>\n",
       "      <td>-5.905937</td>\n",
       "      <td>1.886477</td>\n",
       "      <td>-1.895576</td>\n",
       "      <td>1.543533</td>\n",
       "      <td>-0.810744</td>\n",
       "      <td>-2.179936</td>\n",
       "      <td>-0.246353</td>\n",
       "      <td>-1.648335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-4.469362</td>\n",
       "      <td>-0.442265</td>\n",
       "      <td>-5.633330</td>\n",
       "      <td>1.932214</td>\n",
       "      <td>-2.087591</td>\n",
       "      <td>1.550326</td>\n",
       "      <td>-0.380979</td>\n",
       "      <td>-2.164635</td>\n",
       "      <td>-0.510933</td>\n",
       "      <td>-1.565828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-4.532681</td>\n",
       "      <td>-0.512775</td>\n",
       "      <td>-5.877450</td>\n",
       "      <td>2.047004</td>\n",
       "      <td>-1.948693</td>\n",
       "      <td>1.651096</td>\n",
       "      <td>-0.687145</td>\n",
       "      <td>-2.229399</td>\n",
       "      <td>-0.393133</td>\n",
       "      <td>-1.675275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-4.419697</td>\n",
       "      <td>-0.470240</td>\n",
       "      <td>-5.912309</td>\n",
       "      <td>2.073251</td>\n",
       "      <td>-1.983343</td>\n",
       "      <td>1.477294</td>\n",
       "      <td>-0.642327</td>\n",
       "      <td>-2.315076</td>\n",
       "      <td>-0.520057</td>\n",
       "      <td>-1.736542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-4.326933</td>\n",
       "      <td>-0.461193</td>\n",
       "      <td>-5.816375</td>\n",
       "      <td>1.885792</td>\n",
       "      <td>-1.858116</td>\n",
       "      <td>1.540111</td>\n",
       "      <td>-0.527380</td>\n",
       "      <td>-2.145002</td>\n",
       "      <td>-0.542805</td>\n",
       "      <td>-1.752264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-4.162858</td>\n",
       "      <td>-0.391251</td>\n",
       "      <td>-5.638585</td>\n",
       "      <td>1.995135</td>\n",
       "      <td>-1.939742</td>\n",
       "      <td>1.604459</td>\n",
       "      <td>-0.590095</td>\n",
       "      <td>-1.865212</td>\n",
       "      <td>-0.473297</td>\n",
       "      <td>-1.569633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-4.468704</td>\n",
       "      <td>-0.599918</td>\n",
       "      <td>-5.771778</td>\n",
       "      <td>1.771264</td>\n",
       "      <td>-2.141885</td>\n",
       "      <td>1.683494</td>\n",
       "      <td>-0.811214</td>\n",
       "      <td>-2.218258</td>\n",
       "      <td>-0.553553</td>\n",
       "      <td>-1.832131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-4.579349</td>\n",
       "      <td>-0.470828</td>\n",
       "      <td>-5.637471</td>\n",
       "      <td>1.993889</td>\n",
       "      <td>-2.235622</td>\n",
       "      <td>1.481609</td>\n",
       "      <td>-0.634582</td>\n",
       "      <td>-2.243541</td>\n",
       "      <td>-0.670675</td>\n",
       "      <td>-1.815938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-4.431774</td>\n",
       "      <td>-0.285640</td>\n",
       "      <td>-5.582947</td>\n",
       "      <td>1.806934</td>\n",
       "      <td>-2.121514</td>\n",
       "      <td>1.535908</td>\n",
       "      <td>-0.595368</td>\n",
       "      <td>-2.175062</td>\n",
       "      <td>-0.427077</td>\n",
       "      <td>-1.662670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-4.387476</td>\n",
       "      <td>-0.366782</td>\n",
       "      <td>-5.664843</td>\n",
       "      <td>1.866545</td>\n",
       "      <td>-1.971349</td>\n",
       "      <td>1.567302</td>\n",
       "      <td>-0.434183</td>\n",
       "      <td>-1.984872</td>\n",
       "      <td>-0.568292</td>\n",
       "      <td>-1.698327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -4.343514 -0.470205 -5.780606  1.961841 -1.940944  1.399573 -0.673334   \n",
       "1  -4.468988 -0.463305 -5.871291  1.982735 -1.889553  1.412642 -0.520311   \n",
       "2  -4.511020 -0.452256 -5.814909  2.135624 -1.987322  1.300354 -0.469966   \n",
       "3  -4.562456 -0.198412 -5.874629  2.334005 -2.022654  1.461627 -0.308126   \n",
       "4  -4.438083 -0.645153 -5.910209  2.030208 -1.800816  1.501837 -0.417466   \n",
       "5  -4.478323 -0.378768 -5.769333  2.025003 -1.893234  1.627165 -0.494353   \n",
       "6  -4.504324 -0.588872 -5.946111  1.963259 -1.849977  1.485801 -0.706335   \n",
       "7  -4.479429 -0.530021 -5.837025  2.141378 -2.090778  1.547986 -0.558126   \n",
       "8  -4.414129 -0.365094 -6.136842  2.138390 -2.010524  1.420078 -0.367815   \n",
       "9  -4.542788 -0.681623 -5.881545  2.023903 -2.266980  1.632286 -0.901849   \n",
       "10 -4.425818 -0.689757 -5.806067  2.111423 -2.031722  1.469004 -0.759572   \n",
       "11 -4.527795 -0.568058 -5.848974  1.994722 -1.967229  1.660657 -0.609224   \n",
       "12 -4.566021 -0.158057 -5.641023  2.227514 -1.876553  1.791280 -0.359609   \n",
       "13 -4.515719 -0.527349 -5.812649  2.197331 -1.981195  1.678271 -0.517956   \n",
       "14 -4.415989 -0.499141 -5.693619  2.100939 -2.035962  1.558091 -0.646224   \n",
       "15 -4.204714 -0.624371 -6.104282  2.207796 -2.011225  1.520842 -0.869734   \n",
       "16 -4.417226 -0.410155 -5.668110  2.149332 -2.028780  1.590480 -0.309961   \n",
       "17 -4.491939 -0.725661 -5.905937  1.886477 -1.895576  1.543533 -0.810744   \n",
       "18 -4.469362 -0.442265 -5.633330  1.932214 -2.087591  1.550326 -0.380979   \n",
       "19 -4.532681 -0.512775 -5.877450  2.047004 -1.948693  1.651096 -0.687145   \n",
       "20 -4.419697 -0.470240 -5.912309  2.073251 -1.983343  1.477294 -0.642327   \n",
       "21 -4.326933 -0.461193 -5.816375  1.885792 -1.858116  1.540111 -0.527380   \n",
       "22 -4.162858 -0.391251 -5.638585  1.995135 -1.939742  1.604459 -0.590095   \n",
       "23 -4.468704 -0.599918 -5.771778  1.771264 -2.141885  1.683494 -0.811214   \n",
       "24 -4.579349 -0.470828 -5.637471  1.993889 -2.235622  1.481609 -0.634582   \n",
       "25 -4.431774 -0.285640 -5.582947  1.806934 -2.121514  1.535908 -0.595368   \n",
       "26 -4.387476 -0.366782 -5.664843  1.866545 -1.971349  1.567302 -0.434183   \n",
       "\n",
       "           7         8         9  \n",
       "0  -2.169806 -0.438555 -1.526194  \n",
       "1  -2.189789 -0.365389 -1.491480  \n",
       "2  -2.525029 -0.454924 -1.668514  \n",
       "3  -2.261543 -0.714481 -1.573503  \n",
       "4  -2.207183 -0.373309 -1.511065  \n",
       "5  -2.301847 -0.527648 -1.520270  \n",
       "6  -2.229362 -0.316175 -1.557958  \n",
       "7  -2.502913 -0.464672 -1.473361  \n",
       "8  -2.320865 -0.614544 -1.740168  \n",
       "9  -2.412902 -0.430513 -1.623027  \n",
       "10 -2.307801 -0.607591 -1.600415  \n",
       "11 -2.246560 -0.651440 -1.632452  \n",
       "12 -2.079988 -0.849005 -1.845268  \n",
       "13 -2.225466 -0.500846 -1.490168  \n",
       "14 -2.313899 -0.452682 -1.717500  \n",
       "15 -2.228696 -0.431966 -1.647368  \n",
       "16 -2.133852 -0.686246 -1.767470  \n",
       "17 -2.179936 -0.246353 -1.648335  \n",
       "18 -2.164635 -0.510933 -1.565828  \n",
       "19 -2.229399 -0.393133 -1.675275  \n",
       "20 -2.315076 -0.520057 -1.736542  \n",
       "21 -2.145002 -0.542805 -1.752264  \n",
       "22 -1.865212 -0.473297 -1.569633  \n",
       "23 -2.218258 -0.553553 -1.832131  \n",
       "24 -2.243541 -0.670675 -1.815938  \n",
       "25 -2.175062 -0.427077 -1.662670  \n",
       "26 -1.984872 -0.568292 -1.698327  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = pd.DataFrame(y)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94df1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "siteid = [\"site\" + str(i) for i in id]\n",
    "print(siteid)\n",
    "y2.index = siteid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bb1e88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>site63</th>\n",
       "      <td>-4.343514</td>\n",
       "      <td>-0.470205</td>\n",
       "      <td>-5.780606</td>\n",
       "      <td>1.961841</td>\n",
       "      <td>-1.940944</td>\n",
       "      <td>1.399573</td>\n",
       "      <td>-0.673334</td>\n",
       "      <td>-2.169806</td>\n",
       "      <td>-0.438555</td>\n",
       "      <td>-1.526194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site146</th>\n",
       "      <td>-4.468988</td>\n",
       "      <td>-0.463305</td>\n",
       "      <td>-5.871291</td>\n",
       "      <td>1.982735</td>\n",
       "      <td>-1.889553</td>\n",
       "      <td>1.412642</td>\n",
       "      <td>-0.520311</td>\n",
       "      <td>-2.189789</td>\n",
       "      <td>-0.365389</td>\n",
       "      <td>-1.491480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site152</th>\n",
       "      <td>-4.511020</td>\n",
       "      <td>-0.452256</td>\n",
       "      <td>-5.814909</td>\n",
       "      <td>2.135624</td>\n",
       "      <td>-1.987322</td>\n",
       "      <td>1.300354</td>\n",
       "      <td>-0.469966</td>\n",
       "      <td>-2.525029</td>\n",
       "      <td>-0.454924</td>\n",
       "      <td>-1.668514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site154</th>\n",
       "      <td>-4.562456</td>\n",
       "      <td>-0.198412</td>\n",
       "      <td>-5.874629</td>\n",
       "      <td>2.334005</td>\n",
       "      <td>-2.022654</td>\n",
       "      <td>1.461627</td>\n",
       "      <td>-0.308126</td>\n",
       "      <td>-2.261543</td>\n",
       "      <td>-0.714481</td>\n",
       "      <td>-1.573503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site165</th>\n",
       "      <td>-4.438083</td>\n",
       "      <td>-0.645153</td>\n",
       "      <td>-5.910209</td>\n",
       "      <td>2.030208</td>\n",
       "      <td>-1.800816</td>\n",
       "      <td>1.501837</td>\n",
       "      <td>-0.417466</td>\n",
       "      <td>-2.207183</td>\n",
       "      <td>-0.373309</td>\n",
       "      <td>-1.511065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site167</th>\n",
       "      <td>-4.478323</td>\n",
       "      <td>-0.378768</td>\n",
       "      <td>-5.769333</td>\n",
       "      <td>2.025003</td>\n",
       "      <td>-1.893234</td>\n",
       "      <td>1.627165</td>\n",
       "      <td>-0.494353</td>\n",
       "      <td>-2.301847</td>\n",
       "      <td>-0.527648</td>\n",
       "      <td>-1.520270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site171</th>\n",
       "      <td>-4.504324</td>\n",
       "      <td>-0.588872</td>\n",
       "      <td>-5.946111</td>\n",
       "      <td>1.963259</td>\n",
       "      <td>-1.849977</td>\n",
       "      <td>1.485801</td>\n",
       "      <td>-0.706335</td>\n",
       "      <td>-2.229362</td>\n",
       "      <td>-0.316175</td>\n",
       "      <td>-1.557958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site176</th>\n",
       "      <td>-4.479429</td>\n",
       "      <td>-0.530021</td>\n",
       "      <td>-5.837025</td>\n",
       "      <td>2.141378</td>\n",
       "      <td>-2.090778</td>\n",
       "      <td>1.547986</td>\n",
       "      <td>-0.558126</td>\n",
       "      <td>-2.502913</td>\n",
       "      <td>-0.464672</td>\n",
       "      <td>-1.473361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site197</th>\n",
       "      <td>-4.414129</td>\n",
       "      <td>-0.365094</td>\n",
       "      <td>-6.136842</td>\n",
       "      <td>2.138390</td>\n",
       "      <td>-2.010524</td>\n",
       "      <td>1.420078</td>\n",
       "      <td>-0.367815</td>\n",
       "      <td>-2.320865</td>\n",
       "      <td>-0.614544</td>\n",
       "      <td>-1.740168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site199</th>\n",
       "      <td>-4.542788</td>\n",
       "      <td>-0.681623</td>\n",
       "      <td>-5.881545</td>\n",
       "      <td>2.023903</td>\n",
       "      <td>-2.266980</td>\n",
       "      <td>1.632286</td>\n",
       "      <td>-0.901849</td>\n",
       "      <td>-2.412902</td>\n",
       "      <td>-0.430513</td>\n",
       "      <td>-1.623027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site206</th>\n",
       "      <td>-4.425818</td>\n",
       "      <td>-0.689757</td>\n",
       "      <td>-5.806067</td>\n",
       "      <td>2.111423</td>\n",
       "      <td>-2.031722</td>\n",
       "      <td>1.469004</td>\n",
       "      <td>-0.759572</td>\n",
       "      <td>-2.307801</td>\n",
       "      <td>-0.607591</td>\n",
       "      <td>-1.600415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site208</th>\n",
       "      <td>-4.527795</td>\n",
       "      <td>-0.568058</td>\n",
       "      <td>-5.848974</td>\n",
       "      <td>1.994722</td>\n",
       "      <td>-1.967229</td>\n",
       "      <td>1.660657</td>\n",
       "      <td>-0.609224</td>\n",
       "      <td>-2.246560</td>\n",
       "      <td>-0.651440</td>\n",
       "      <td>-1.632452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site226</th>\n",
       "      <td>-4.566021</td>\n",
       "      <td>-0.158057</td>\n",
       "      <td>-5.641023</td>\n",
       "      <td>2.227514</td>\n",
       "      <td>-1.876553</td>\n",
       "      <td>1.791280</td>\n",
       "      <td>-0.359609</td>\n",
       "      <td>-2.079988</td>\n",
       "      <td>-0.849005</td>\n",
       "      <td>-1.845268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site244</th>\n",
       "      <td>-4.515719</td>\n",
       "      <td>-0.527349</td>\n",
       "      <td>-5.812649</td>\n",
       "      <td>2.197331</td>\n",
       "      <td>-1.981195</td>\n",
       "      <td>1.678271</td>\n",
       "      <td>-0.517956</td>\n",
       "      <td>-2.225466</td>\n",
       "      <td>-0.500846</td>\n",
       "      <td>-1.490168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site248</th>\n",
       "      <td>-4.415989</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-5.693619</td>\n",
       "      <td>2.100939</td>\n",
       "      <td>-2.035962</td>\n",
       "      <td>1.558091</td>\n",
       "      <td>-0.646224</td>\n",
       "      <td>-2.313899</td>\n",
       "      <td>-0.452682</td>\n",
       "      <td>-1.717500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site264</th>\n",
       "      <td>-4.204714</td>\n",
       "      <td>-0.624371</td>\n",
       "      <td>-6.104282</td>\n",
       "      <td>2.207796</td>\n",
       "      <td>-2.011225</td>\n",
       "      <td>1.520842</td>\n",
       "      <td>-0.869734</td>\n",
       "      <td>-2.228696</td>\n",
       "      <td>-0.431966</td>\n",
       "      <td>-1.647368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site277</th>\n",
       "      <td>-4.417226</td>\n",
       "      <td>-0.410155</td>\n",
       "      <td>-5.668110</td>\n",
       "      <td>2.149332</td>\n",
       "      <td>-2.028780</td>\n",
       "      <td>1.590480</td>\n",
       "      <td>-0.309961</td>\n",
       "      <td>-2.133852</td>\n",
       "      <td>-0.686246</td>\n",
       "      <td>-1.767470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site300</th>\n",
       "      <td>-4.491939</td>\n",
       "      <td>-0.725661</td>\n",
       "      <td>-5.905937</td>\n",
       "      <td>1.886477</td>\n",
       "      <td>-1.895576</td>\n",
       "      <td>1.543533</td>\n",
       "      <td>-0.810744</td>\n",
       "      <td>-2.179936</td>\n",
       "      <td>-0.246353</td>\n",
       "      <td>-1.648335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site318</th>\n",
       "      <td>-4.469362</td>\n",
       "      <td>-0.442265</td>\n",
       "      <td>-5.633330</td>\n",
       "      <td>1.932214</td>\n",
       "      <td>-2.087591</td>\n",
       "      <td>1.550326</td>\n",
       "      <td>-0.380979</td>\n",
       "      <td>-2.164635</td>\n",
       "      <td>-0.510933</td>\n",
       "      <td>-1.565828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site331</th>\n",
       "      <td>-4.532681</td>\n",
       "      <td>-0.512775</td>\n",
       "      <td>-5.877450</td>\n",
       "      <td>2.047004</td>\n",
       "      <td>-1.948693</td>\n",
       "      <td>1.651096</td>\n",
       "      <td>-0.687145</td>\n",
       "      <td>-2.229399</td>\n",
       "      <td>-0.393133</td>\n",
       "      <td>-1.675275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site394</th>\n",
       "      <td>-4.419697</td>\n",
       "      <td>-0.470240</td>\n",
       "      <td>-5.912309</td>\n",
       "      <td>2.073251</td>\n",
       "      <td>-1.983343</td>\n",
       "      <td>1.477294</td>\n",
       "      <td>-0.642327</td>\n",
       "      <td>-2.315076</td>\n",
       "      <td>-0.520057</td>\n",
       "      <td>-1.736542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site411</th>\n",
       "      <td>-4.326933</td>\n",
       "      <td>-0.461193</td>\n",
       "      <td>-5.816375</td>\n",
       "      <td>1.885792</td>\n",
       "      <td>-1.858116</td>\n",
       "      <td>1.540111</td>\n",
       "      <td>-0.527380</td>\n",
       "      <td>-2.145002</td>\n",
       "      <td>-0.542805</td>\n",
       "      <td>-1.752264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site413</th>\n",
       "      <td>-4.162858</td>\n",
       "      <td>-0.391251</td>\n",
       "      <td>-5.638585</td>\n",
       "      <td>1.995135</td>\n",
       "      <td>-1.939742</td>\n",
       "      <td>1.604459</td>\n",
       "      <td>-0.590095</td>\n",
       "      <td>-1.865212</td>\n",
       "      <td>-0.473297</td>\n",
       "      <td>-1.569633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site416</th>\n",
       "      <td>-4.468704</td>\n",
       "      <td>-0.599918</td>\n",
       "      <td>-5.771778</td>\n",
       "      <td>1.771264</td>\n",
       "      <td>-2.141885</td>\n",
       "      <td>1.683494</td>\n",
       "      <td>-0.811214</td>\n",
       "      <td>-2.218258</td>\n",
       "      <td>-0.553553</td>\n",
       "      <td>-1.832131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site417</th>\n",
       "      <td>-4.579349</td>\n",
       "      <td>-0.470828</td>\n",
       "      <td>-5.637471</td>\n",
       "      <td>1.993889</td>\n",
       "      <td>-2.235622</td>\n",
       "      <td>1.481609</td>\n",
       "      <td>-0.634582</td>\n",
       "      <td>-2.243541</td>\n",
       "      <td>-0.670675</td>\n",
       "      <td>-1.815938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site444</th>\n",
       "      <td>-4.431774</td>\n",
       "      <td>-0.285640</td>\n",
       "      <td>-5.582947</td>\n",
       "      <td>1.806934</td>\n",
       "      <td>-2.121514</td>\n",
       "      <td>1.535908</td>\n",
       "      <td>-0.595368</td>\n",
       "      <td>-2.175062</td>\n",
       "      <td>-0.427077</td>\n",
       "      <td>-1.662670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site458</th>\n",
       "      <td>-4.387476</td>\n",
       "      <td>-0.366782</td>\n",
       "      <td>-5.664843</td>\n",
       "      <td>1.866545</td>\n",
       "      <td>-1.971349</td>\n",
       "      <td>1.567302</td>\n",
       "      <td>-0.434183</td>\n",
       "      <td>-1.984872</td>\n",
       "      <td>-0.568292</td>\n",
       "      <td>-1.698327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "site63  -4.343514 -0.470205 -5.780606  1.961841 -1.940944  1.399573 -0.673334   \n",
       "site146 -4.468988 -0.463305 -5.871291  1.982735 -1.889553  1.412642 -0.520311   \n",
       "site152 -4.511020 -0.452256 -5.814909  2.135624 -1.987322  1.300354 -0.469966   \n",
       "site154 -4.562456 -0.198412 -5.874629  2.334005 -2.022654  1.461627 -0.308126   \n",
       "site165 -4.438083 -0.645153 -5.910209  2.030208 -1.800816  1.501837 -0.417466   \n",
       "site167 -4.478323 -0.378768 -5.769333  2.025003 -1.893234  1.627165 -0.494353   \n",
       "site171 -4.504324 -0.588872 -5.946111  1.963259 -1.849977  1.485801 -0.706335   \n",
       "site176 -4.479429 -0.530021 -5.837025  2.141378 -2.090778  1.547986 -0.558126   \n",
       "site197 -4.414129 -0.365094 -6.136842  2.138390 -2.010524  1.420078 -0.367815   \n",
       "site199 -4.542788 -0.681623 -5.881545  2.023903 -2.266980  1.632286 -0.901849   \n",
       "site206 -4.425818 -0.689757 -5.806067  2.111423 -2.031722  1.469004 -0.759572   \n",
       "site208 -4.527795 -0.568058 -5.848974  1.994722 -1.967229  1.660657 -0.609224   \n",
       "site226 -4.566021 -0.158057 -5.641023  2.227514 -1.876553  1.791280 -0.359609   \n",
       "site244 -4.515719 -0.527349 -5.812649  2.197331 -1.981195  1.678271 -0.517956   \n",
       "site248 -4.415989 -0.499141 -5.693619  2.100939 -2.035962  1.558091 -0.646224   \n",
       "site264 -4.204714 -0.624371 -6.104282  2.207796 -2.011225  1.520842 -0.869734   \n",
       "site277 -4.417226 -0.410155 -5.668110  2.149332 -2.028780  1.590480 -0.309961   \n",
       "site300 -4.491939 -0.725661 -5.905937  1.886477 -1.895576  1.543533 -0.810744   \n",
       "site318 -4.469362 -0.442265 -5.633330  1.932214 -2.087591  1.550326 -0.380979   \n",
       "site331 -4.532681 -0.512775 -5.877450  2.047004 -1.948693  1.651096 -0.687145   \n",
       "site394 -4.419697 -0.470240 -5.912309  2.073251 -1.983343  1.477294 -0.642327   \n",
       "site411 -4.326933 -0.461193 -5.816375  1.885792 -1.858116  1.540111 -0.527380   \n",
       "site413 -4.162858 -0.391251 -5.638585  1.995135 -1.939742  1.604459 -0.590095   \n",
       "site416 -4.468704 -0.599918 -5.771778  1.771264 -2.141885  1.683494 -0.811214   \n",
       "site417 -4.579349 -0.470828 -5.637471  1.993889 -2.235622  1.481609 -0.634582   \n",
       "site444 -4.431774 -0.285640 -5.582947  1.806934 -2.121514  1.535908 -0.595368   \n",
       "site458 -4.387476 -0.366782 -5.664843  1.866545 -1.971349  1.567302 -0.434183   \n",
       "\n",
       "                7         8         9  \n",
       "site63  -2.169806 -0.438555 -1.526194  \n",
       "site146 -2.189789 -0.365389 -1.491480  \n",
       "site152 -2.525029 -0.454924 -1.668514  \n",
       "site154 -2.261543 -0.714481 -1.573503  \n",
       "site165 -2.207183 -0.373309 -1.511065  \n",
       "site167 -2.301847 -0.527648 -1.520270  \n",
       "site171 -2.229362 -0.316175 -1.557958  \n",
       "site176 -2.502913 -0.464672 -1.473361  \n",
       "site197 -2.320865 -0.614544 -1.740168  \n",
       "site199 -2.412902 -0.430513 -1.623027  \n",
       "site206 -2.307801 -0.607591 -1.600415  \n",
       "site208 -2.246560 -0.651440 -1.632452  \n",
       "site226 -2.079988 -0.849005 -1.845268  \n",
       "site244 -2.225466 -0.500846 -1.490168  \n",
       "site248 -2.313899 -0.452682 -1.717500  \n",
       "site264 -2.228696 -0.431966 -1.647368  \n",
       "site277 -2.133852 -0.686246 -1.767470  \n",
       "site300 -2.179936 -0.246353 -1.648335  \n",
       "site318 -2.164635 -0.510933 -1.565828  \n",
       "site331 -2.229399 -0.393133 -1.675275  \n",
       "site394 -2.315076 -0.520057 -1.736542  \n",
       "site411 -2.145002 -0.542805 -1.752264  \n",
       "site413 -1.865212 -0.473297 -1.569633  \n",
       "site416 -2.218258 -0.553553 -1.832131  \n",
       "site417 -2.243541 -0.670675 -1.815938  \n",
       "site444 -2.175062 -0.427077 -1.662670  \n",
       "site458 -1.984872 -0.568292 -1.698327  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6df1b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y2.to_csv('D:/Program Files/R/Rfile/SC_FL_CD/1023/valVector.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae564d-0995-4631-a830-168520006592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bd6fa-07bd-48ab-b993-155db5f9f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c371d-e22b-4364-a5c3-641bc3db6353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45225ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9f8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7195c0-0f73-4080-8615-33609202ab4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed0fd2-f022-42f0-960a-694fe9b276d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
